{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TW5Nj9pGnHzq",
        "aJtqGxIyqQCC",
        "_LhsTu4M5Hqa"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### importing the dataset from kaggle"
      ],
      "metadata": {
        "id": "TW5Nj9pGnHzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i49b4I9YnQnZ",
        "outputId": "4caf15db-1e6b-49e2-8d94-a0c045cb13f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp '/content/drive/MyDrive/Kaggle/kaggle.json' '/content'"
      ],
      "metadata": {
        "id": "f14tnmMcnSmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\""
      ],
      "metadata": {
        "id": "8c73wZ0YnfsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d vuppalaadithyasairam/bone-fracture-detection-using-xrays"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELJDD7Aon3dW",
        "outputId": "b8ab9234-96a8-485f-9898-10967b91750c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading bone-fracture-detection-using-xrays.zip to /content\n",
            " 99% 170M/172M [00:06<00:00, 25.4MB/s]\n",
            "100% 172M/172M [00:06<00:00, 26.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('bone-fracture-detection-using-xrays.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "XEIixMBKn-Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len(os.listdir('/tmp/archive (6)/train'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDteWDNiobNX",
        "outputId": "c34abe1b-f2bc-4de9-c95a-9f4169a515a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing images\n"
      ],
      "metadata": {
        "id": "aJtqGxIyqQCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "pT4nokfUqTB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    validation_split = 0.2\n",
        ")"
      ],
      "metadata": {
        "id": "Spb8JLIlsWeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_generator = generator.flow_from_directory(\n",
        "    \"/tmp/archive (6)/train\",\n",
        "    target_size = (224, 224),\n",
        "    batch_size = 16,\n",
        "    class_mode =\"binary\",\n",
        "    subset = \"training\"\n",
        ")\n",
        "\n",
        "Validation_generator = generator.flow_from_directory(\n",
        "    \"/tmp/archive (6)/train\",\n",
        "    target_size = (224, 224),\n",
        "    batch_size = 16,\n",
        "    class_mode =\"binary\",\n",
        "    subset = \"validation\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RRY8IyxsdtY",
        "outputId": "e78f7b7f-76be-4d0b-e1a7-f5b80f6fdfe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7091 images belonging to 2 classes.\n",
            "Found 1772 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train_generator.next()[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5wmbsGEtvdi",
        "outputId": "9dd6bc23-3ae6-4921-e5ad-a45c00fa89a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Validation_generator.next()[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTY4090KtyLy",
        "outputId": "e8d484c4-cc26-4df1-c55c-7eec3895af1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Developing the model"
      ],
      "metadata": {
        "id": "_LhsTu4M5Hqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "h74wqaqnv0iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.Xception(\n",
        "    weights=None,\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False)"
      ],
      "metadata": {
        "id": "zTW-48fQv3uN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True"
      ],
      "metadata": {
        "id": "H79O2-FOv6VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "x = base_model(inputs, training=True)\n",
        "x = keras.layers.GaussianNoise(0.25)(x)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dense(512,activation='relu')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "x = keras.layers.GaussianNoise(0.25)(x)\n",
        "x = keras.layers.Dropout(0.25)(x)\n",
        "outputs = keras.layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "W8RrfZ8rv_Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import callbacks"
      ],
      "metadata": {
        "id": "mlAUADIjwBeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlyStopping = keras.callbacks.EarlyStopping(\n",
        "    patience=7,\n",
        ")\n",
        "\n",
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "l4L8SIGfwDb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "V5QcfBpjwFfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(Train_generator, epochs=5,\n",
        "          callbacks=[earlyStopping,model_checkpoint_callback ],\n",
        "          validation_data=Validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ajtrVMEwHXB",
        "outputId": "2be7448f-7412-4e58-afc8-af3e6a6c7100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "444/444 [==============================] - ETA: 0s - loss: 0.6517 - accuracy: 0.6579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r444/444 [==============================] - 199s 350ms/step - loss: 0.6517 - accuracy: 0.6579 - val_loss: 0.8015 - val_accuracy: 0.5293\n",
            "Epoch 2/5\n",
            "444/444 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.8280"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r444/444 [==============================] - 152s 343ms/step - loss: 0.3854 - accuracy: 0.8280 - val_loss: 1.3540 - val_accuracy: 0.5688\n",
            "Epoch 3/5\n",
            "444/444 [==============================] - ETA: 0s - loss: 0.2087 - accuracy: 0.9158"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r444/444 [==============================] - 152s 343ms/step - loss: 0.2087 - accuracy: 0.9158 - val_loss: 1.2125 - val_accuracy: 0.5942\n",
            "Epoch 4/5\n",
            "444/444 [==============================] - ETA: 0s - loss: 0.1130 - accuracy: 0.9612"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 40). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r444/444 [==============================] - 153s 344ms/step - loss: 0.1130 - accuracy: 0.9612 - val_loss: 1.3113 - val_accuracy: 0.6044\n",
            "Epoch 5/5\n",
            "444/444 [==============================] - 128s 289ms/step - loss: 0.1019 - accuracy: 0.9650 - val_loss: 1.6938 - val_accuracy: 0.5412\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f73cc2deb60>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(Train_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHTIM4P34PmW",
        "outputId": "82efed5a-77c8-4a36-f633-6cdb5209cce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "444/444 [==============================] - 37s 82ms/step - loss: 0.0539 - accuracy: 0.9766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0539282001554966, 0.9765900373458862]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test_Generator = generator.flow_from_directory(\n",
        "    \"/tmp/archive (6)/val\",\n",
        "    target_size = (224, 224),\n",
        "    batch_size = 16,\n",
        "    class_mode =\"binary\",\n",
        "    subset = \"training\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWjqoojo4yOE",
        "outputId": "90d14034-13b5-4fb4-aca3-adee72fb9ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 480 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(Test_Generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzHdcu4o4_1a",
        "outputId": "352de357-6986-4048-91dd-4dac0f8b5e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 3s 82ms/step - loss: 2.3392 - accuracy: 0.6042\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3391671180725098, 0.6041666865348816]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}